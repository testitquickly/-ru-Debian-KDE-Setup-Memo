Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2024-11-30T21:46:21+02:00

====== Whisper ======

[ @sound @openai @whisper ]

Для преобразования аудиофайлов в текст можно использовать automatic speech recognition (ASR) «Whisper» от OpenAI. Это функциональная модель распознавания речи с открытым исходным кодом, поддерживает множество языков (русский и украинский) и работает локально. Применяется MIT License.

===== Установка =====

* [[Debian:Install:Whisper]]

===== Использование Whisper =====

==== Предварительная конвертация аудио ====

Whisper работает лучше с аудио в формате WAV с частотой 16 кГц. Если файлы записаны в другом формате, можно конвертировать их через ffmpeg:

''ffmpeg -i your_audio_file.mp3 -ar 16000 -ac 1 output.wav''

Если надо конвертировать ВСЕ mp3-файлы в каталоге:

''for file in /INPUT_FOLDER/*.mp3; do ffmpeg -i "$file" -ar 16000 -ac 1 "${file%.mp3}.wav"; done''

Может быть удобнее обработать файлы из одного каталога и сохранить сконвертированные файлы в другом каталоге:

''for file in /INPUT_FOLDER/*.mp3; do ffmpeg -i "$file" -ar 16000 -ac 1 "/OUTPUT_FOLDER/$(basename "${file%.mp3}.wav")"; done''

===== Включить Whisper =====

Перейти в каталог с уже созданным (при установке Whisper) виртуальным окружением Python:

''cd ~/whisper/''

Активировать его:

''source whisper_env/bin/activate''

Для выхода из виртуального окружения надо выполнить в том же каталоге команду ''deactivate''

==== Преобразовать в текст один аудиофайл ====

У Whisper есть несколько моделей:

* tiny, base: Быстро, меньшая точность.
* small, medium: Баланс между точностью и скоростью.
* large: Высокая точность, но требует больше ресурсов.
* turbo: Быстро.

Пример использования

''whisper АУДИОФАЙЛ.mp3 --language Russian --model medium''

В каталоге, из которого запущена команда — в моём случае это ''~/whisper/'' — появится несколько файлов с расшифрованным текстом:
*.json
*.srt
*.tsv
*.txt
*.vtt

В *.json записывается какой-то RTF-подобный текст:

''{"text": " \u0441 \u0447\u0435\u0433\u043e \u043e\u0431\u044b\u0447\u043d\u043e \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f…''

В *.txt текст записан сплошным потоком, без знаков препинания — очень неудобно для восприятия.

В *.vtt записан WEBVTT (Web Video Text Tracks) — это формат субтитров, используемый в веб-приложениях и поддерживаемый HTML5. В *.srt то же самое, только ещё и с нумерацией реплик. 

В принципе файл *.vtt — самый удобный для восприятия.

Чтобы не создавать множество текстовых файлов на каждую расшифровку, можно указать Whisper формат нужного файла, и только он один и будет создан:

''whisper АУДИОФАЙЛ.mp3 --language Russian --model medium --output_format vtt''

Если обрабатываемый «АУДИОФАЙЛ.mp3» находится в другом каталоге, то разумно сохранить расшифровку рядом с ним:

'''
FILE="/home/astenix/Аудио/1min.wav"; whisper $FILE --language Russian --model medium --output_dir "$(dirname $FILE)" --output_format vtt
'''

Кавычки нужны на случай если в полном пути к файлу будут пробелы.

==== Преобразовать в текст несколько аудиофайлов ====

Преобразовать все аудиофайлы в цикле в отдельном каталоге через модель “turbo”:

'''
FOLDER="/home/astenix/Аудио"; for FILE in $FOLDER/*.wav; do whisper "$FILE" --language Russian --model medium --output_dir "$(dirname "$FILE")" --output_format vtt; done
'''

===== Условности =====

* wav на один голос, моно, 1 min = 5 Mb, с внятной речью, через модель ''small'' выполняется за 1 мин 15 сек.
* wav на один голос, моно, 5 min = 25 Mb, с внятной речью, через модель ''small'' выполняется за 07 мин 10 сек.
* wav на один голос, моно, 10 min = 50 Mb…

Каждая модель Whisper перед первым её применением будет загружена из сети. Модель „small” на момент тестирования весит 461 МБ. Модель „large” [[https://github.com/openai/whisper/blob/main/README.md#available-models-and-languages|потребует]] скачать почти три гигабайта. Каждая модель сохраняется где-то в кэше профиля пользователя.

На большом количестве файлов Whisper в принципе может заставить гудеть кулерами даже ноутбук, в котором в принципе нет вентиляторов. Поэтому на ноутбуке без выделенного GPU разумно запускать Whisper через модель „turbo”. Пусть она менее точна и условно хуже справляется с аудио, в котором много лишнего шума, но она менее ресурсоёмкая. Да и качество текста после транскрибации всё равно неоднозначное, в него очень сложно вчитываться, его надо читать  одновременно с фонограммой.

Опять же из сострадания к ресурсам компьютера надо очень придирчиво отбирать, какие файлы действительно надо транскрибировать, а какие нет.
