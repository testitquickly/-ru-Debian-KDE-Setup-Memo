Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2024-11-30T21:46:21+02:00

====== Whisper ======

[ @sound @openai @whisper ]

Для преобразования аудиофайлов в текст можно использовать automatic speech recognition (ASR) «Whisper» от OpenAI. Это функциональная модель распознавания речи с открытым исходным кодом, поддерживает множество языков (русский и украинский) и работает локально. Применяется MIT License.

===== Установка =====

* [[Debian:Установка ПО:Whisper]]

===== Использование Whisper =====

==== Предварительная конвертация аудио ====

Whisper работает лучше с аудио в формате WAV с частотой 16 кГц. Если файлы записаны в другом формате, можно конвертировать их через ffmpeg:

''ffmpeg -i your_audio_file.mp3 -ar 16000 -ac 1 output.wav''

Если надо конвертировать ВСЕ mp3-файлы в каталоге:

''for file in /INPUT_FOLDER/*.mp3; do ffmpeg -i "$file" -ar 16000 -ac 1 "${file%.mp3}.wav"; done''

Может быть удобнее обработать файлы из одного каталога и сохранить сконвертированные файлы в другом каталоге:

''for file in /INPUT_FOLDER/*.mp3; do ffmpeg -i "$file" -ar 16000 -ac 1 "/OUTPUT_FOLDER/$(basename "${file%.mp3}.wav")"; done''

==== Преобразовать в текст один аудиофайл ====

Есть несколько моделей:

* tiny, base: Быстро, меньшая точность.
* small, medium: Баланс между точностью и скоростью.
* large: Высокая точность, но требует больше ресурсов.

''whisper АУДИОФАЙЛ.mp3 --language Russian --model medium''

В каталоге, из которого запущена команда — в моём случае это ''~/whisper/'' — появится несколько файлов с расшифрованным текстом:
*.json
*.srt
*.tsv
*.txt
*.vtt

В *.json записывается какой-то RTF-подобный текст:

''{"text": " \u0441 \u0447\u0435\u0433\u043e \u043e\u0431\u044b\u0447\u043d\u043e \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f…''

В *.txt текст записан сплошным потоком, без знаков препинания — очень неудобно для восприятия.

В *.vtt записан WEBVTT (Web Video Text Tracks) — это формат субтитров, используемый в веб-приложениях и поддерживаемый HTML5. В *.srt то же самое, только ещё и с нумерацией реплик. 

В принципе файл *.vtt — самый удобный для восприятия.

Чтобы не создавать множество файлов на каждую расшифровку, можно указать Whisper формат нужного файла, и только он один и будет создан:

''whisper АУДИОФАЙЛ.mp3 --language Russian --model medium --output_format srt''

Если обрабатываемый «АУДИОФАЙЛ.mp3» находится в другом каталоге, то разумно сохранить расшифровку рядом с ним:

'''
FILE="/home/astenix/Аудио/1min.wav"; whisper $FILE --language Russian --model medium --output_dir "$(dirname $FILE)" --output_format vtt
'''

Кавычки нужны на случай если в полном пути к файлу будут пробелы.

==== Преобразовать в текст несколько аудиофайлов ====

Преобразовать все аудиофайлы в каталоге через модель “medium” в цикле:

''for file in /INPUT_FOLDER/*.wav; do whisper "$file" --language Russian --model medium > "/OUTPUT_FOLDER/$(basename "$file" .wav).txt" done''

===== Условности =====

* wav на один голос, моно, 1 min = 5 Mb
* wav на один голос, моно, 5 min = 25 Mb
* wav на один голос, моно, 10 min = 50 Mb

Конечно, многое зависит от количества RAM и особенностей процессора, но условно обработка аудиофайла 
* «на 1 минуту разговора» 
* с внятной речью 
* через модель ''small''
* с подключением к сети
происходит за 1 мин 15 сек.

Файл на 5 минут с теми же параметрами был обработан за 07 мин 10 сек.

Каждая модель Whisper перед первым её применением будет загружена из сети. small на момент тестирования весит 461 МБ. Модель ''large'' [[https://github.com/openai/whisper/blob/main/README.md#available-models-and-languages|потребует]] скачать почти три гигабайта. Скачанная модель сохраняется где-то в кэше. 

Если есть видеокарта GPU с CUDA, Whisper использует её автоматически и скорость работы повысится, надо только установить драйверы CUDA и библиотеку PyTorch:

''pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118''

