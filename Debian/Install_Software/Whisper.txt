Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2024-12-01T00:30:56+02:00

====== Whisper ======

[ @debian @install @sound @openai @whisper ]

Нужен Python и его virtual environment

''sudo apt install python3.11-venv''

и ещё

''sudo apt install ffmpeg''

Сделать каталог для всего этого дела

''mkdir whisper && cd whisper/''

Создать virtual environment для проекта

''python3 -m venv whisper_env''

Активировать его

''source whisper_env/bin/activate''

Для выхода из виртуального окружения надо выполнить в том же каталоге команду ''deactivate''

Важно: нельзя перемещать каталог ''whisper_env''. Если очень надо, то следует сделать новый virtual environment для проекта в новом каталоге.

Снять файлы из git и установить Whisper и все зависимости

''pip install git+https://github.com/openai/whisper.git''

Если есть видеокарта GPU с CUDA, надо 

1. 
установить подходящие драйверы для неё — [[Nvidia]]

2. 
узнать версию CUDA, совместимую с вашей системой.

''nvidia-smi''

В ответе посмотреть 

''Driver Version: 525.85.12''
''CUDA Version: 12.0''

Драйверы CUDA должны были быть установлены отдельно на этапе установке драйверов для Nvidia.

3. 
Установить библиотеку PyTorch:

Тут такое дело — драйвера Nvidia и библиотека PyTorch прямо не связаны. Сейчас у меня установлена CUDA 12.6, у PyTorch есть скомпилированные драйвера только для CUDA 12.4 В принципе можно скомпилировать драйвера посвежее самому, но без подготовки заниматься этим вряд ли получится. Поэтому рекомендуется поставить последние доступные драйвера и надеяться на то, что они сработают.

Эту команду надо запускать в виртуальном окружении Python, которое поднято для работы Whisper:

''pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124''

Зайти в интерпретатор python

''python3''

Выполнить последовательно

'''
import torch
'''

''print(torch.cuda.is_available())''

В ответ ожидаем ''True''.

Выход по ''Ctrl+D''.

Дальше надеемся, что Whisper в работе будет использовать GPU.

См. [[Software:Whisper]]
